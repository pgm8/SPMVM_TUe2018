
import numpy as np
import pandas as pd
from PreProcessor import PreProcessor
from ModuleManager import ModuleManager
from TechnicalAnalyzer import TechnicalAnalyzer

import matplotlib.pyplot as plt
import os

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

#  Set seed for pseudorandom number generator. This allows us to reproduce the results from our script.
np.random.seed(42)


def main():
    preprocesser = PreProcessor()
    mm = ModuleManager()
    ta = TechnicalAnalyzer()

    ##################################################################################################################
    ###                         Dow Jones Industrial Averages 30 Constituents log returns                          ###
    ##################################################################################################################
    """
    filename = 'multivariate_analysis/DJI30_returns_raw.csv'
    path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                        ('resources/Data/%s' % filename))
    df = pd.read_csv(path)
    mm.save_data('multivariate_analysis/DJI30_returns_1987_2001.pkl', df)
    mm.transform_pickle_to_csv('multivariate_analysis/DJI30_returns_1987_2001.pkl')
    # Descriptive statistics asset log returns
    """
    """
    data_stat = mm.load_data('multivariate_analysis/DJI30_returns_1987_2001.pkl')
    data_stat.drop(columns='Date', inplace=True)
    data_stat.reset_index(drop=True, inplace=True)
    # Initialise dataframe
    df_stats = pd.DataFrame(data={'Asset': list(data_stat)})
    df_stats.set_index('Asset', inplace=True)
    # Mean
    df_stats['Mean'] = data_stat.mean(axis=0)
    # St. Error
    df_stats['St. error'] = data_stat.sem(axis=0)
    # Skewness
    df_stats['Skewness'] = data_stat.skew(axis=0)
    # Excess Kurtosis
    df_stats['Excess kurtosis'] = data_stat.kurtosis(axis=0)
    # Minimum
    df_stats['Minimum'] = data_stat.min(axis=0)
    # Maximum
    df_stats['Maximum'] = data_stat.max(axis=0)
    mm.save_data('multivariate_analysis/DJI30_returns_stats_1987_2001.pkl', df_stats)
    mm.transform_pickle_to_csv('multivariate_analysis/DJI30_returns_stats_1987_2001.pkl')
    """
    ##################################################################################################################
    ###                                          Dataset creation                                                  ###
    ##################################################################################################################
    # Moving window estimates as approximation for true correlation constructing set of covariates and output variable
    # Dataframe with DJI 30 constituents
    """"
    dt = 10
    proxy_type = ['pearson, ''kendall']
    data = mm.load_data('multivariate_analysis/DJI30_returns_1987_2001.pkl')
    dates = data['Date']
    dates.reset_index(drop=True, inplace=True)
    data.drop(['Date'], axis=1, inplace=True)
    for proxy_type in proxy_type:
        dataset = preprocesser.generate_multivariate_dataset(ta, data=data, dt=dt, proxy_type=proxy_type)
        result = pd.concat([dates, dataset], axis=1, join='inner')
        result.dropna(axis=0, inplace=True)
        result.reset_index(drop=True, inplace=True)
        mm.save_data('multivariate_analysis/%s/data/dataset_DJI30_%s_%i_1987_2001.pkl'
                     % (proxy_type, proxy_type, dt), result)
        mm.transform_pickle_to_csv('multivariate_analysis/%s/data/dataset_DJI30_%s_%i_1987_2001.pkl' 
                     % (proxy_type, proxy_type, dt))
    """
    ##################################################################################################################
    ###                  Time-varying pair wise correlation estimation using machine learning                      ###
    ##################################################################################################################
    # Estimate correlations for stable market conditions: 03/01/1995 - 31/12/1999
    # Estimate correlations for volatile market conditions: 02/01/2004 - 31/12/2008
    """
    dt = 10
    n = 30  # Number of assets under consideration
    n_corr = int((n*(n-1)) / 2)
    #T = 504   # length of out-of-sample test set tranquil market conditions 1994-1995
    T = 500    # length of out-of-sample test set volatile market conditions 2000-2001
    proxy_type = ['pearson', 'kendall']
    n_neighbors = 5
    n_estimators = [10]     # [10, 100]

    for n_estimators, proxy_type in [(x, y) for x in n_estimators for y in proxy_type]:
        data = mm.load_data('multivariate_analysis/%s/data/dataset_DJI30_%s_%i_1987_2001.pkl'
                            % (proxy_type, proxy_type, dt))
        mm.transform_pickle_to_csv('multivariate_analysis/%s/data/dataset_DJI30_%s_%i_1987_2001.pkl'
                            % (proxy_type, proxy_type, dt))

        data.drop(columns='Date', inplace=True)
        #data = data[1:(2220-dt)]  # 31/3/1987 - 29/12/1995
        #data = data                # 31/3/1987 - 12/31/1999
        headers = list(data.columns.values[:n_corr])
        rho_estimates = pd.DataFrame(columns=headers)
        t_train_init = data.shape[0] - T

        for j, t in enumerate(range(t_train_init, data.shape[0])):  #  j={0:503/ 0:499}
            print((n_estimators, proxy_type, j, t))
            sample = np.asarray(data.iloc[j:t, :])  # True rolling window is [j:t, :]
            x_test = np.asarray(data.iloc[t, :n_corr+2])  # This is in fact x_t+1
            X = np.asarray(sample[:, :n_corr+2])  # covariate matrix (vectorize data for speed up)
            y = np.asarray(sample[:, -n_corr:])  # response vector
            X_train, y_train = X[:t, :], y[:t]
            #knn = KNeighborsRegressor(n_neighbors=len(X_train), weights='distance').fit(X_train, y_train)  # n_neighbors=len(X_train)
            #rho_estimate = knn.predict(x_test.reshape(1, -1))
            rf = RandomForestRegressor(n_estimators=n_estimators, max_features=int((X.shape[1]) / 3)).fit(X_train, y_train)
            rho_estimate = rf.predict(x_test.reshape(1, -1))
            df = pd.DataFrame(rho_estimate, columns=headers)
            rho_estimates = pd.merge(rho_estimates, df, how='outer')
    """
    """
        mm.save_data('multivariate_analysis/%s/%s_cor_estimates/cor_knn_idw_%s_%i_DJI30_%s.pkl' %
                     (proxy_type, proxy_type, proxy_type, dt, period), rho_estimates)
        mm.transform_pickle_to_csv('multivariate_analysis/%s/%s_cor_estimates/cor_knn_idw_%s_%i_DJI30_%s.pkl' %
                                   (proxy_type, proxy_type, proxy_type, dt, period))

        mm.save_data('multivariate_analysis/%s/%s_cor_estimates/cor_knn_idw_%s_%i_DJI30_2000_2001.pkl' %
                     (proxy_type, proxy_type, proxy_type, dt), rho_estimates)
        mm.transform_pickle_to_csv('multivariate_analysis/%s/%s_cor_estimates/cor_knn_idw_%s_%i_DJI30_2000_2001.pkl' %
                                   (proxy_type, proxy_type, proxy_type, dt))

    """
    """
    mm.save_data('multivariate_analysis/%s/%s_cor_estimates/cor_rf%i_%s_%i_DJI30_2000_2001.pkl' %
                     (proxy_type, proxy_type, n_estimators, proxy_type, dt), rho_estimates)
    mm.transform_pickle_to_csv('multivariate_analysis/%s/%s_cor_estimates/cor_rf%i_%s_%i_DJI30_2000_20001.pkl' %
                                   (proxy_type, proxy_type, n_estimators, proxy_type, dt))
    """
    ##################################################################################################################
    ###                                   Minimum Determinant Learning Algorithms                                       ###
    ##################################################################################################################
    # Compute matrix determinants for all time t in stable period
    """
    n = 30  # Number of assets under consideration
    T = 253
    dt = 10
    period = ['volatile']  # ['stable', 'volatile'] run separately
    proxy_type = ['pearson', 'kendall']
    for period, proxy_type in [(x, y) for x in period for y in proxy_type]:
        det_min_vec = np.full(T, np.nan)
        data_cor = mm.load_data('multivariate_analysis/%s/%s_cor_estimates/cor_knn_idw_%s_%i_DJI30_%s.pkl' %
                                (proxy_type, proxy_type, proxy_type, dt, period))
        for row in range(0, T):
            det_min_vec[row] = preprocesser.determinant_LU_factorization(data_cor.iloc[row, :], n)
        filename = 'determinant_knn_idw_%s_%i_DJI30_%s.pkl' % (proxy_type, dt, period)
        mm.save_data('multivariate_analysis/%s/det_results_%s/%s' % (proxy_type, proxy_type, filename), det_min_vec)
    """
    """
    # Plot determinants of time-varying correlation matrices obtained from KNN
    #det_knn5_pearson = mm.load_data('multivariate_analysis/pearson/det_results_pearson/determinant_knn5_pearson_10_DJI30_stable.pkl')
    #det_knn5_kendall = mm.load_data('multivariate_analysis/kendall/det_results_kendall/determinant_knn5_kendall_10_DJI30_stable.pkl')
    det_knn5_pearson_volatile = mm.load_data('multivariate_analysis/pearson/det_results_pearson/determinant_knn5_pearson_10_DJI30_volatile.pkl')
    det_knn5_kendall_volatile = mm.load_data('multivariate_analysis/kendall/det_results_kendall/determinant_knn5_kendall_10_DJI30_volatile.pkl')

    #det_knn_idw_pearson = mm.load_data('multivariate_analysis/pearson/det_results_pearson/determinant_knn_idw_pearson_10_DJI30_stable.pkl')
    #det_knn_idw_kendall = mm.load_data('multivariate_analysis/kendall/det_results_kendall/determinant_knn_idw_kendall_10_DJI30_stable.pkl')
    det_knn_idw_pearson_volatile = mm.load_data('multivariate_analysis/pearson/det_results_pearson/determinant_knn_idw_pearson_10_DJI30_volatile.pkl')
    det_knn_idw_kendall_volatile = mm.load_data('multivariate_analysis/kendall/det_results_kendall/determinant_knn_idw_kendall_10_DJI30_volatile.pkl')

    print(np.min(det_knn_idw_pearson_volatile))
    print(np.min(det_knn_idw_kendall_volatile))

    plt.figure(1)
    plt.plot(det_knn_idw_pearson_volatile, label='KNN_pearson', linewidth=1, color='orange')
    plt.plot(det_knn_idw_kendall_volatile, label='KNN_kendall', linewidth=1)
    plt.xlabel('observation')
    plt.ylabel('det($R_t)$')
    plt.legend(fontsize='small', loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=2, fancybox=True,
               edgecolor='black')
    plt.xlim(0, 250)
    plt.yticks(np.arange(-0.1, 1.1, 0.1))
    plt.ylim(-0.1, 1)
    plt.show()
    """


###############################
####         MAIN          ####
###############################
if __name__ == '__main__':
    main()
