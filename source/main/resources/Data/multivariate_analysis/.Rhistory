dccGarch_mvt_tranquil <-  dcc_garch_modeling_alt(data=a_t, t=t, distribution.model="std", distribution="mvt")
dccGarch_mvt_tranquil$D_t_file
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
data <- df[1:2224,]  # Data sample: 17/3/1987-29/12/1995
View(data)
t
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
data <- df[1:2224,]  # Data sample: 17/3/1987-29/12/1995
data$Date <- NULL
View(data)
data$Date <- NULL
T <- 504  # Out-of-sample test sample: 3/1/1994-29/12/1995
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
View(data)
T <- 504  # Out-of-sample test sample: 3/1/1994-29/12/1995
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
## Dynamic Conditional Correlation model with various error distributions
dccGarch_mvnorm_tranquil <- dcc_garch_modeling_alt(data=a_t, t=t, distribution.model="norm", distribution="mvnorm")
View(dccGarch_mvnorm_tranquil)
# Write matrices containing time-varying volatilies and correlations to csv file
# Add column names to file containing conditional correlations
col_names <- read.csv(file="pearson/pearson_cor_estimates/cor_knn5_pearson_10_DJI30_1994_1995.csv", row.names=1)
colnames(dccGarch_mvt_tranquil$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
colnames(dccGarch_mvnorm_tranquil$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
# Choose to either do rolling forward or extending horizon. Check this by comparing performance and take most favourable
write.csv(dccGarch_mvnorm_tranquil$D_t_file, file="volatilities_mvnorm_DJI30_1994_1995_alt.csv")
write.csv(dccGarch_mvnorm_tranquil$R_t_file, file="cor_DCC_mvnorm_DJI30_1994_1995_alt.csv")
source("R/fun_VaR_backtesting.R")
dccGarch_mvt_tranquil <-  dcc_garch_modeling(data=a_t, t=t, distribution.model="std", distribution="mvt")
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Volatile Market Conditions                              #######
####################################################################################################
data <- df  # Data sample: 17/3/1987-31/12/2001
data$Date <- NULL
T <- 500  # Out-of-sample test sample: 3/1/2000-31/12/2001
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
## Dynamic Conditional Correlation model with various error distributions
dccGarch_mvnorm_vol <- dcc_garch_modeling(data=a_t, t=t, distribution.model="norm", distribution="mvnorm")
dccGarch_mvt_vol <-  dcc_garch_modeling(data=a_t, t=t, distribution.model="std", distribution="mvt")
# Write matrices containing time-varying volatilies and correlations to csv file
# Add column names to file containing conditional correlations
col_names <- read.csv(file="pearson/pearson_cor_estimates/cor_knn5_pearson_10_DJI30_1994_1995.csv", row.names=1)
colnames(dccGarch_mvnorm_vol$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
colnames(dccGarch_mvt_vol$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
write.csv(dccGarch_mvnorm_vol$D_t_file, file="volatilities_mvnorm_DJI30_2000_2001.csv")
write.csv(dccGarch_mvnorm_vol$R_t_file, file="cor_DCC_mvnorm_DJI30_2000_2001.csv")
write.csv(dccGarch_mvt_vol$D_t_file, file="volatilities_mvt_DJI30_2000_2001.csv")
write.csv(dccGarch_mvt_vol$R_t_file, file="cor_DCC_mvt_DJI30_2000_2001.csv")
View(dccGarch_mvnorm_vol)
View(dccGarch_mvt_vol)
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
data <- df[1:2224,]  # Data sample: 17/3/1987-29/12/1995
data$Date <- NULL
T <- 504  # Out-of-sample test sample: 3/1/1994-29/12/1995
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
# Same first stage conditional mean filtration (sample mean)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
## Dynamic Conditional Correlation model with various error distributions
dccGarch_mvnorm_tranquil <- dcc_garch_modeling(data=a_t, t=t, distribution.model="std", distribution="mvnorm")
set.seed(42)  # 42:The answer to life, the universe and everything.
source("R/fun_VaR_backtesting.R")
## Dynamic Conditional Correlation model with various error distributions
dccGarch_mvnorm_tranquil <- dcc_garch_modeling(data=a_t, t=t, distribution.model="std", distribution="mvnorm")
View(dcc_garch_modeling)
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
data <- df[1:2224,]  # Data sample: 17/3/1987-29/12/1995
data$Date <- NULL
T <- 504  # Out-of-sample test sample: 3/1/1994-29/12/1995
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
# Same first stage conditional mean filtration (sample mean)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
## Dynamic Conditional Correlation model with various error distributions
dccGarch_mvnorm_tranquil <- dcc_garch_modeling(data=a_t, t=t, distribution.model="std", distribution="mvnorm")
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
data <- df[1:2224,]  # Data sample: 17/3/1987-29/12/1995
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
data <- df[1:2224,]  # Data sample: 17/3/1987-29/12/1995
data$Date <- NULL
T <- 504  # Out-of-sample test sample: 3/1/1994-29/12/1995
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
# Same first stage conditional mean filtration (sample mean)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
dccGarch_mvt_tranquil <-  dcc_garch_modeling(data=a_t, t=t, distribution.model="norm", distribution="mvt")
# Write matrices containing time-varying volatilies and correlations to csv file
# Add column names to file containing conditional correlations
col_names <- read.csv(file="pearson/pearson_cor_estimates/cor_knn5_pearson_10_DJI30_1994_1995.csv", row.names=1)
colnames(dccGarch_mvt_tranquil$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
write.csv(dccGarch_mvt_tranquil$D_t_file, file="volatilities_norm_mvt_DJI30_1994_1995.csv")
write.csv(dccGarch_mvt_tranquil$R_t_file, file="cor_DCC_norm_mvt_DJI30_1994_1995.csv")
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(rugarch)
library(rmgarch)
library(parallel)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
# Data sample import
setwd("~/Documents/Python/PycharmProjects/thesisOML/ml_tue2017/source/main/resources/Data/multivariate_analysis")
df <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)
####################################################################################################
######                               Volatile Market Conditions                              #######
####################################################################################################
data <- df  # Data sample: 17/3/1987-31/12/2001
data$Date <- NULL
T <- 500  # Out-of-sample test sample: 3/1/2000-31/12/2001
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
dccGarch_mvt_vol <-  dcc_garch_modeling(data=a_t, t=t, distribution.model="norm", distribution="mvt")
dccGarch_mvt_vol <-  dcc_garch_modeling(data=a_t, t=t, distribution.model="norm", distribution="mvt")
# Write matrices containing time-varying volatilies and correlations to csv file
# Add column names to file containing conditional correlations
col_names <- read.csv(file="pearson/pearson_cor_estimates/cor_knn5_pearson_10_DJI30_1994_1995.csv", row.names=1)
colnames(dccGarch_mvnorm_vol$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
write.csv(dccGarch_mvt_vol$R_t_file, file="cor_DCC_norm_mvt_DJI30_2000_2001.csv")
# Write matrices containing time-varying volatilies and correlations to csv file
# Add column names to file containing conditional correlations
col_names <- read.csv(file="pearson/pearson_cor_estimates/cor_knn5_pearson_10_DJI30_1994_1995.csv", row.names=1)
colnames(dccGarch_mvnorm_vol$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
colnames(dccGarch_mvt_vol$R_t_file) <- c(colnames(col_names))[1:(N*(N-1)/2)]
write.csv(dccGarch_mvt_vol$D_t_file, file="volatilities_norm_mvt_DJI30_2000_2001.csv")
write.csv(dccGarch_mvt_vol$R_t_file, file="cor_DCC_norm_mvt_DJI30_2000_2001.csv")
rm(list=ls())  # remove all variables in R
library(chemometrics)
install.packages("chemometrics")
library(chemometrics)
data(glass)
View(glass)
data(glass.grp)
x=glass[,c(2,7)]
require(robustbase)
x.mcd=covMcd(x)
drawMahal(x,center=x.mcd$center,covariance=x.mcd$cov,quantile=0.90)
View(glass)
drawMahal(x,center=x.mcd$center,covariance=x.mcd$cov,quantile=0..05)
drawMahal(x,center=x.mcd$center,covariance=x.mcd$cov,quantile=0.05)
drawMahal(x,center=x.mcd$center,covariance=x.mcd$cov,quantile=0.99)
drawMahal(x,center=x.mcd$center,covariance=x.mcd$cov,quantile=0.90)
drawMahal(x,center=x.mcd$center,covariance=x.mcd$cov,quantile=0.90)
load("/Users/pmelkert/Downloads/data.rda")
View(x.mcd)
View(lane2)
install.packages("integratedMRF")
install.packages("IntegratedMRF")
rm(list=ls())  # remove all variables in R
library(IntegratedMRF)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)
trainY=matrix(runif(50*5),50,5)
View(trainY)
View(trainX)
testX=matrix(runif(10*100),10,100)
View(testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)  # 100 features
trainY=matrix(runif(50*5),50,5)      # 5 responses
n_tree=2
m_feature= 33
min_leaf=1
testX=matrix(runif(10*100),10,100)  # 10 test samples
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
n_tree=10
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)  # 100 features
trainY=matrix(runif(50*100),50,100)  # 100 responses
n_tree=10
m_feature= 33
min_leaf=1
testX=matrix(runif(10*100),10,100)  # 10 test samples
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
View(testX)
trainY=matrix(runif(50*100),50,50)  # 100 responses
n_tree=10
m_feature= 33
min_leaf=1
testX=matrix(runif(10*50),10,50)  # 10 test samples
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)  # 100 features
trainY=matrix(runif(50*5),50,5)      # 50 features
n_tree=2
m_feature=5
min_leaf=5
testX=matrix(runif(10*100),10,100)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
View(trainY)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)      # 100 features
trainY=matrix(runif(50*100),50,100)      # 100 responses
n_tree=10
m_feature=33
min_leaf=1
testX=matrix(runif(10*100),10,100)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)      # 100 features
trainY=matrix(runif(50*100),50,99)      # 100 responses
trainY=matrix(runif(50*99),50,99)      # 100 responses
n_tree=10
m_feature=33
min_leaf=1
testX=matrix(runif(10*100),10,100)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)  # 100 features
trainY=matrix(runif(50*100),50,100)      # 100 responses
n_tree=10
m_feature= 33
min_leaf=1
testX=matrix(runif(10*100),10,100)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)
trainY=matrix(runif(50*5),50,5)
n_tree=2
m_feature=5
min_leaf=5
testX=matrix(runif(10*100),10,100)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*100),50,100)
trainY=matrix(runif(50*5),50,5)
n_tree=100
m_feature=33
min_leaf=1
testX=matrix(runif(10*100),10,100)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
View(Prediction)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*200),50,200)
trainY=matrix(runif(50*5),50,5)
n_tree=100
m_feature=33
min_leaf=1
testX=matrix(runif(10*200),10,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*200),50,200)
trainY=matrix(runif(50*5),50,5)
n_tree=10
m_feature=33
min_leaf=1
testX=matrix(runif(10*200),10,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*200),50,200)
trainY=matrix(runif(50*20),50,20)
n_tree=10
m_feature=33
min_leaf=1
testX=matrix(runif(10*200),10,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
len(trainX)
length(trainX)
dim(trainX)
dim(trainX)[1]
dim(trainX)[2]
dim(trainX)[2] /3
ceiling(dim(trainX)/3)
ceiling(dim(trainX)[1]/3)
ceiling(dim(trainX)[2]/3)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*200),50,200)
trainY=matrix(runif(50*20),50,20)
n_tree=10
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(10*200),10,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
testX=matrix(runif(1*200),1,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
View(Prediction)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*200),50,200)
trainY=matrix(runif(50*20),50,20)
n_tree=10
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*200),1,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*435),50,435)
n_tree=10
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
View(testX)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*200),50,200)
n_tree=10
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*200),50,200)
trainY=matrix(runif(50*20),50,20)
n_tree=10
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*200),1,200)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*20),50,20)
n_tree=10
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*200),50,200)
n_tree=1
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
source("R/fun_VaR_backtesting.R")
rm(list=ls())  # remove all variables in R
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*200),50,200)
n_tree=1
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
rm(list=ls())  # remove all variables in R
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*200),50,200)
n_tree=1
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
#Input and Output Feature Matrix of random data (created using runif)
trainX=matrix(runif(50*437),50,437)
trainY=matrix(runif(50*435),50,435)
n_tree=1
m_feature=ceiling(dim(trainX)[2]/3)
min_leaf=1
testX=matrix(runif(1*437),1,437)
#Prediction size is 10 x 5, where 10 is the number
#of testing samples and 5 is the number of output features
tic <- Sys.time()
Prediction=build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
print(Sys.time()-tic)
View(build_forest_predict)
View(build_forest_predict)
detach("package:chemometrics", unload=TRUE)
